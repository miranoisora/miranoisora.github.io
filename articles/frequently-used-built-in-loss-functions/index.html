
<!DOCTYPE html>

    <html lang="zh-Hant-CN"></html>

    
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="雨天等放晴">
    <title>深度學習中一些常用的內建損失函数 - 雨天等放晴</title>
    <meta name="author" content="Tang Huan">
    
        <meta name="keywords" content="PyTorch,Deep Learning,Loss Functions,損失函數,损失函数">
    
    
        <link rel="icon" href="https://tangh.github.io/assets/images/favicon.png">
    
    
        <link rel="apple-touch-icon" sizes="180x180" href="https://tangh.github.io/assets/images/apple-touch-icon.png">
    
    
    <script type="application/ld+json">{"@context":"http://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Tang Huan","sameAs":["https://twitter.com/tanghrtx/","https://www.flickr.com/photos/135277712@N07/","https://www.instagram.com/tanghrtx/","https://www.youtube.com/channel/UCO-I0MZR6-HYmI_tgbBc0yw/","https://space.bilibili.com/634428/"],"image":"icon.jpg"},"articleBody":"\n\n\n這是最近的第二篇，目前只寫了交叉熵，以後有時間會加上別的。\n交叉熵（CrossEntropy）這應該是與分類相關最常見的一個損失函数，在目標檢測中對每個框的類別分数，和語義分割中對每個像素點的類別置信度訓練時，也都可以使用這個損失函数。語義分割中的每一個像素就等效於目標檢測中的一個框，和圖像分類中的一整張圖。\n在 PyTorch 中，交叉熵在 nn.CrossEntropyLoss，它其實就是把 nn.LogSoftmax 和 nn.NLLLoss 兩個合在一起。對於 LogSoftmax，也就是在 softmax 的值上求了一个對数：\n$$\\text{LogSoftmax}(x_i) = log(\\frac{exp(x_i)}{\\sum_j exp(x_j)})$$\n但是使用 LogSoftmax 比分成兩步数值上會更穩定，因為當輸入值過小時，在 softmax 後向下溢出而变為 0，那麼在 log 之後就會是無限大；當輸入值過大時，在 softmax 中的指数計算可能會向上溢出。而計算 log 時可對分子分母同時除以最大的指数值：\n$$\\begin{aligned}log[f(x_i)] &amp; = log(\\frac {\\frac{e^{x_i}}{e^M}} {\\frac{e^{x_1}}{e^M} + \\frac{e^{x_2}}{e^M} + \\cdots + \\frac{e^{x_n}}{e^M}})\\ = \\ log(\\frac{e^{x_i - M}}{\\sum_j e^{x_j - M}}) \\\\&amp; = log(e^{x_i - M}) - log(\\sum_j e^{x_j - M}) \\\\&amp; = (x_i - M) - log(\\sum_j e^{x_j - M})\\end{aligned}$$\nj 表示的是對某一個像素（或一個框或一張圖）所有類別的概率。這樣就避免了上述問題，同時可以看到計算速度會加快不少。對輸出的每個值都在類別通道上完成上述計算之後，NLLLoss (negative log likelihood loss) 就是對每一個像素，取出這個像素正確標籤對應的通道上的值，取相反数，然後相加。\nclass NLLLoss() 在構造時有三個參数，一個是 weight，表示對某一個類別，取出來值取相反数後，乘上一個權重；另一個是 ignore_index，表示真實標籤中需要忽略的值，一般圖像中边界和無法辨別的區域會用一個負值標記；reduction=&quot;mean&quot; 表示對所有像素求和之後，除以整個 batch 中所有像素数量，而 &quot;sum&quot; 表示求和後直接輸出，&quot;none&quot; 表示直接輸出数組。\n下面測試一下，假設是目標檢測，共出了 3 對匹配框（整個 batch），總共有 4 類，那麼 cls 分数應是一個 (3, 4) 的 tensor，而 GT 應該是 (3，) tensor：\n1234567891011121314prediction = torch.rand(2, 3, 4)&gt;&gt;&gt; tensor([[0.1046, 0.0606, 0.5262, 0.7876],            [0.8600, 0.1484, 0.8924, 0.7151],            [0.2049, 0.9825, 0.2194, 0.8449]])target = torch.tensor([0, 2, 1])log_sm = F.log_softmax(prediction, dim=1)&gt;&gt;&gt; tensor([[-1.6976, -1.7417, -1.2761, -1.0147],            [-1.2205, -1.9321, -1.1881, -1.3654],            [-1.8062, -1.0286, -1.7918, -1.1662]])nlll = nn.NLLLoss(reduction=\"mean\")nlll(log_sm, target)&gt;&gt;&gt; tensor(1.3048)\n\n手動計算一下 loss：(1.6976 + 1.1881 + 1.0286) / 3 = 1.30477。\n對於 nn.CrossEntropyLoss，如前所述，就是把兩步合在了一起，所以它的公式如下：\n$$\\text{CELoss} (x, \\text{class}) = - log(\\frac{e^{x[class]}}{\\sum_j e^{x[j]}}) = -x[class] + log(\\sum_j e^{x[j]})$$\n它的參数也與 NLLLoss 相同，這裡我們以一個 Batch Size = 2, classes = 3, size = (3, 3) 的輸出為例，即語義分割任務，看看兩者是不是相等的：\n123456789101112131415prediction = torch.rand(2, 3, 3, 3)# 語義分割 GT 需要 NHW，int64 格式target = torch.tensor([    [[0,2,1],[0,2,1],[0,2,1]],    [[0,2,1],[0,2,1],[0,2,1]]])log_sm = F.log_softmax(prediction, dim=1)nlll = nn.NLLLoss(reduction=\"sum\")print(nlll(log_sm, target) / 18)&gt;&gt;&gt; tensor(1.1208)cel = nn.CrossEntropyLoss(reduction=\"mean\")print(cel(prediction, target))&gt;&gt;&gt; tensor(1.1208)\n\n可以看到二者結果完全相同。\n交叉熵還有一個二元（Binary）形式的 nn.BCELoss，它要求 GT 只能是 0 或 1 兩個值，比如 Faster R-CNN 中的 RPN 模塊的訓練就可以使用它，只有兩類後，公式簡化如下：\n$$l_n = -w_n [y_n \\cdot log(x_n) + (1-y_n) \\cdot log(1-x_n) ]$$\n","dateCreated":"2020-03-31T00:00:00+08:00","dateModified":"2020-04-20T21:07:15+08:00","datePublished":"2020-03-31T00:00:00+08:00","description":"一些深度學習中常用的損失函数，以及它們在 PyTorch 中的使用和行為。","headline":"深度學習中一些常用的內建損失函数","image":[],"mainEntityOfPage":{"@type":"WebPage","@id":"https://tangh.github.io/articles/frequently-used-built-in-loss-functions/"},"publisher":{"@type":"Organization","name":"Tang Huan","sameAs":["https://twitter.com/tanghrtx/","https://www.flickr.com/photos/135277712@N07/","https://www.instagram.com/tanghrtx/","https://www.youtube.com/channel/UCO-I0MZR6-HYmI_tgbBc0yw/","https://space.bilibili.com/634428/"],"image":"icon.jpg","logo":{"@type":"ImageObject","url":"icon.jpg"}},"url":"https://tangh.github.io/articles/frequently-used-built-in-loss-functions/","keywords":"Deep Learning, PyTorch"}</script>
    <meta name="description" content="一些深度學習中常用的損失函数，以及它們在 PyTorch 中的使用和行為。">
<meta property="og:type" content="blog">
<meta property="og:title" content="深度學習中一些常用的內建損失函数">
<meta property="og:url" content="https:&#x2F;&#x2F;tangh.github.io&#x2F;articles&#x2F;frequently-used-built-in-loss-functions&#x2F;">
<meta property="og:site_name" content="雨天等放晴">
<meta property="og:description" content="一些深度學習中常用的損失函数，以及它們在 PyTorch 中的使用和行為。">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2020-03-30T16:00:00.000Z">
<meta property="article:modified_time" content="2020-04-20T13:07:15.579Z">
<meta property="article:author" content="Tang Huan">
<meta property="article:tag" content="PyTorch">
<meta property="article:tag" content="Deep Learning">
<meta property="article:tag" content="Loss Functions">
<meta property="article:tag" content="損失函數">
<meta property="article:tag" content="损失函数">
<meta name="twitter:card" content="summary">
    
    
        
    
    
        <meta property="og:image" content="https://tangh.github.io/assets/images/icon.jpg"/>
    
    
    
    
    <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+JP:wght@400;700&family=Noto+Serif+SC:wght@400;700&display=swap" rel="stylesheet">
    <!--STYLES-->
    
<link rel="stylesheet" href="/assets/css/style-iaetwm81hfopcuajcp7qnh2zsnqn4dhiu3nftuj79wdhe7fie6l4r0thrs6g.min.css">

    <!--STYLES END-->
    
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-137837052-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'UA-137837052-1');
    </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->


    

</head>

    <body>
        <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="blog">
            <!-- Define author's picture -->


    
        
            
        
    

<header id="header" data-behavior="4">
    <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
    <div class="header-title">
        <a
            class="header-title-link"
            href="/"
            aria-label=""
        >
            雨天等放晴
        </a>
    </div>
    
        
            <a
                class="header-right-picture "
                href="#about"
                aria-label="Open the link: /#about"
            >
        
        
            <img class="header-picture" src="/assets/images/icon.jpg" alt="Author&#39;s picture"/>
        
        </a>
    
</header>

            <!-- Define author's picture -->



        
    

<nav id="sidebar" data-behavior="4">
    <div class="sidebar-container">
        
            <div class="sidebar-profile">
                <a
                    href="/#about"
                    aria-label="Read more about the author"
                >
                    <img class="sidebar-profile-picture" src="/assets/images/icon.jpg" alt="Author&#39;s picture"/>
                </a>
                <h4 class="sidebar-profile-name">Tang Huan</h4>
                
                    <h5 class="sidebar-profile-bio"></h5>
                
            </div>
        
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/"
                            
                            rel="noopener"
                            title="Home"
                        >
                        <i class="sidebar-button-icon fa fa-home" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Home</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-categories"
                            
                            rel="noopener"
                            title="Categories"
                        >
                        <i class="sidebar-button-icon fa fa-bookmark" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Categories</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-tags"
                            
                            rel="noopener"
                            title="Tags"
                        >
                        <i class="sidebar-button-icon fa fa-tags" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Tags</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/all-archives"
                            
                            rel="noopener"
                            title="Archives"
                        >
                        <i class="sidebar-button-icon fa fa-archive" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Archives</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="/about"
                            
                            rel="noopener"
                            title="About"
                        >
                        <i class="sidebar-button-icon fas fa-cube" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">About</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://twitter.com/tanghrtx/"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="Twitter"
                        >
                        <i class="sidebar-button-icon fab fa-twitter" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Twitter</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://www.flickr.com/photos/135277712@N07/"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="Flickr"
                        >
                        <i class="sidebar-button-icon fab fa-flickr" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Flickr</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://www.instagram.com/tanghrtx/"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="Instagram"
                        >
                        <i class="sidebar-button-icon fab fa-instagram" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Instagram</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://www.youtube.com/channel/UCO-I0MZR6-HYmI_tgbBc0yw/"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="YouTube"
                        >
                        <i class="sidebar-button-icon fab fa-youtube" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">YouTube</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a
                            class="sidebar-button-link "
                            href="https://space.bilibili.com/634428/"
                            
                                target="_blank"
                            
                            rel="noopener"
                            title="BiliBili"
                        >
                        <i class="sidebar-button-icon fab fa-youtube-square" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">BiliBili</span>
                    </a>
            </li>
            
        </ul>
        
    </div>
</nav>

            
            <div id="main" data-behavior="4"
                 class="
                        hasCoverMetaIn
                        ">
                
<article class="post">
    
    
        <div class="post-header main-content-wrap text-center">
    
        <h1 class="post-title">
            深度學習中一些常用的內建損失函数
        </h1>
    
    
        <div class="post-meta">
    <time datetime="2020-03-31T00:00:00+08:00">
	
		    Mar 31, 2020
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/categories/Computer-Science/">Computer Science</a>, <a class="category-link" href="/categories/Computer-Science/Deep-Learning/">Deep Learning</a>


    
</div>

    
</div>

    
    
        <div class="post-content markdown">
    
        <div class="main-content-wrap">
            <!-- excerpt -->


<p>這是最近的第二篇，目前只寫了交叉熵，以後有時間會加上別的。</p>
<h1 id="交叉熵（CrossEntropy）"><a href="#交叉熵（CrossEntropy）" class="headerlink" title="交叉熵（CrossEntropy）"></a>交叉熵（CrossEntropy）</h1><p>這應該是與分類相關最常見的一個損失函数，在目標檢測中對每個框的類別分数，和語義分割中對每個像素點的類別置信度訓練時，也都可以使用這個損失函数。語義分割中的每一個像素就等效於目標檢測中的一個框，和圖像分類中的一整張圖。</p>
<p>在 PyTorch 中，交叉熵在 <a href="https://pytorch.org/docs/stable/nn.html#crossentropyloss" target="_blank" rel="noopener"><code>nn.CrossEntropyLoss</code></a>，它其實就是把 <a href="https://pytorch.org/docs/stable/nn.html#logsoftmax" target="_blank" rel="noopener"><code>nn.LogSoftmax</code></a> 和 <a href="https://pytorch.org/docs/stable/nn.html#nllloss" target="_blank" rel="noopener"><code>nn.NLLLoss</code></a> 兩個合在一起。對於 LogSoftmax，也就是在 softmax 的值上求了一个對数：</p>
<p>$$<br>\text{LogSoftmax}(x_i) = log(\frac{exp(x_i)}{\sum_j exp(x_j)})<br>$$</p>
<p>但是使用 LogSoftmax 比分成兩步数值上會更穩定，因為當輸入值過小時，在 softmax 後向下溢出而变為 0，那麼在 log 之後就會是無限大；當輸入值過大時，在 softmax 中的指数計算可能會向上溢出。而計算 log 時可對分子分母同時除以最大的指数值：</p>
<p>$$<br>\begin{aligned}<br>log[f(x_i)] &amp; = log(\frac {\frac{e^{x_i}}{e^M}} {\frac{e^{x_1}}{e^M} + \frac{e^{x_2}}{e^M} + \cdots + \frac{e^{x_n}}{e^M}})<br>\ = \ log(\frac{e^{x_i - M}}{\sum_j e^{x_j - M}}) \\<br>&amp; = log(e^{x_i - M}) - log(\sum_j e^{x_j - M}) \\<br>&amp; = (x_i - M) - log(\sum_j e^{x_j - M})<br>\end{aligned}<br>$$</p>
<p><code>j</code> 表示的是對某一個像素（或一個框或一張圖）所有類別的概率。這樣就避免了上述問題，同時可以看到計算速度會加快不少。對輸出的每個值都在類別通道上完成上述計算之後，NLLLoss (negative log likelihood loss) 就是對每一個像素，取出這個像素正確標籤對應的通道上的值，取相反数，然後相加。</p>
<p><code>class NLLLoss()</code> 在構造時有三個參数，一個是 <code>weight</code>，表示對某一個類別，取出來值取相反数後，乘上一個權重；另一個是 <code>ignore_index</code>，表示真實標籤中需要忽略的值，一般圖像中边界和無法辨別的區域會用一個負值標記；<code>reduction=&quot;mean&quot;</code> 表示對所有像素求和之後，除以整個 batch 中所有像素数量，而 <code>&quot;sum&quot;</code> 表示求和後直接輸出，<code>&quot;none&quot;</code> 表示直接輸出数組。</p>
<p>下面測試一下，假設是目標檢測，共出了 3 對匹配框（整個 batch），總共有 4 類，那麼 cls 分数應是一個 <code>(3, 4)</code> 的 tensor，而 GT 應該是 <code>(3，)</code> tensor：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">prediction = torch.rand(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tensor([[<span class="number">0.1046</span>, <span class="number">0.0606</span>, <span class="number">0.5262</span>, <span class="number">0.7876</span>],</span><br><span class="line">            [<span class="number">0.8600</span>, <span class="number">0.1484</span>, <span class="number">0.8924</span>, <span class="number">0.7151</span>],</span><br><span class="line">            [<span class="number">0.2049</span>, <span class="number">0.9825</span>, <span class="number">0.2194</span>, <span class="number">0.8449</span>]])</span><br><span class="line"></span><br><span class="line">target = torch.tensor([<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>])</span><br><span class="line">log_sm = F.log_softmax(prediction, dim=<span class="number">1</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tensor([[<span class="number">-1.6976</span>, <span class="number">-1.7417</span>, <span class="number">-1.2761</span>, <span class="number">-1.0147</span>],</span><br><span class="line">            [<span class="number">-1.2205</span>, <span class="number">-1.9321</span>, <span class="number">-1.1881</span>, <span class="number">-1.3654</span>],</span><br><span class="line">            [<span class="number">-1.8062</span>, <span class="number">-1.0286</span>, <span class="number">-1.7918</span>, <span class="number">-1.1662</span>]])</span><br><span class="line"></span><br><span class="line">nlll = nn.NLLLoss(reduction=<span class="string">"mean"</span>)</span><br><span class="line">nlll(log_sm, target)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tensor(<span class="number">1.3048</span>)</span><br></pre></td></tr></table></figure>

<p>手動計算一下 loss：<code>(1.6976 + 1.1881 + 1.0286) / 3 = 1.30477</code>。</p>
<p>對於 <code>nn.CrossEntropyLoss</code>，如前所述，就是把兩步合在了一起，所以它的公式如下：</p>
<p>$$<br>\text{CELoss} (x, \text{class}) = - log(\frac{e^{x[class]}}{\sum_j e^{x[j]}}) = -x[class] + log(\sum_j e^{x[j]})<br>$$</p>
<p>它的參数也與 NLLLoss 相同，這裡我們以一個 <code>Batch Size = 2, classes = 3, size = (3, 3)</code> 的輸出為例，即語義分割任務，看看兩者是不是相等的：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">prediction = torch.rand(<span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line"><span class="comment"># 語義分割 GT 需要 NHW，int64 格式</span></span><br><span class="line">target = torch.tensor([</span><br><span class="line">    [[<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>],[<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>],[<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>]],</span><br><span class="line">    [[<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>],[<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>],[<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>]]</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">log_sm = F.log_softmax(prediction, dim=<span class="number">1</span>)</span><br><span class="line">nlll = nn.NLLLoss(reduction=<span class="string">"sum"</span>)</span><br><span class="line">print(nlll(log_sm, target) / <span class="number">18</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tensor(<span class="number">1.1208</span>)</span><br><span class="line"></span><br><span class="line">cel = nn.CrossEntropyLoss(reduction=<span class="string">"mean"</span>)</span><br><span class="line">print(cel(prediction, target))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tensor(<span class="number">1.1208</span>)</span><br></pre></td></tr></table></figure>

<p>可以看到二者結果完全相同。</p>
<p>交叉熵還有一個二元（Binary）形式的 <a href="https://pytorch.org/docs/stable/nn.html#bceloss" target="_blank" rel="noopener"><code>nn.BCELoss</code></a>，它要求 GT 只能是 <code>0</code> 或 <code>1</code> 兩個值，比如 Faster R-CNN 中的 RPN 模塊的訓練就可以使用它，只有兩類後，公式簡化如下：</p>
<p>$$<br>l_n = -w_n [y_n \cdot log(x_n) + (1-y_n) \cdot log(1-x_n) ]<br>$$</p>
<br/>
            


        </div>
    </div>
    <div id="post-footer" class="post-footer main-content-wrap">
        
            <div class="post-footer-tags">
                <span class="text-color-light text-small">TAGGED IN</span><br/>
                
    <a class="tag tag--primary tag--small t-link" href="/tags/Deep-Learning/" rel="tag">Deep Learning</a> <a class="tag tag--primary tag--small t-link" href="/tags/PyTorch/" rel="tag">PyTorch</a>

            </div>
        
        
            <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/posts/simple-thoughts-on-chinese-characters/"
                    data-tooltip="漢字雜談"
                    aria-label="PREVIOUS: 漢字雜談"
                >
                    
                        <i class="fa fa-angle-left" aria-hidden="true"></i>
                        <span class="hide-xs hide-sm text-small icon-ml">PREVIOUS</span>
                    </a>
            </li>
            <li class="post-action">
                
                    
                <a
                    class="post-action-btn btn btn--default tooltip--top"
                    href="/articles/build-model-and-dataset-in-pytorch/"
                    data-tooltip="PyTorch 中構建模型和輸入数據的方法"
                    aria-label="NEXT: PyTorch 中構建模型和輸入数據的方法"
                >
                    
                        <span class="hide-xs hide-sm text-small icon-mr">NEXT</span>
                        <i class="fa fa-angle-right" aria-hidden="true"></i>
                    </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action hide-lg hide-md hide-sm">
            <a
                class="post-action-btn btn btn--default btn-open-shareoptions"
                href="#btn-open-shareoptions"
                aria-label="Share this post"
            >
                <i class="fa fa-share-alt" aria-hidden="true"></i>
            </a>
        </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://tangh.github.io/articles/frequently-used-built-in-loss-functions/"
                    title="Share on Facebook"
                    aria-label="Share on Facebook"
                >
                    <i class="fab fa-facebook" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="https://twitter.com/intent/tweet?text=https://tangh.github.io/articles/frequently-used-built-in-loss-functions/"
                    title="Share on Twitter"
                    aria-label="Share on Twitter"
                >
                    <i class="fab fa-twitter" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="http://service.weibo.com/share/share.php?&amp;title=https://tangh.github.io/articles/frequently-used-built-in-loss-functions/"
                    title="Share on Weibo"
                    aria-label="Share on Weibo"
                >
                    <i class="fab fa-weibo" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a
                    class="post-action-btn btn btn--default"
                    target="new" href="http://connect.qq.com/widget/shareqq/index.html?url=https://tangh.github.io/articles/frequently-used-built-in-loss-functions/&amp;title=深度學習中一些常用的內建損失函数"
                    title="Share on QQ"
                    aria-label="Share on QQ"
                >
                    <i class="fab fa-qq" aria-hidden="true"></i>
                </a>
            </li>
        
        
            
                <li class="post-action">
                    <a
                        class="post-action-btn btn btn--default"
                        href="#gitalk"
                        aria-label="Leave a comment"
                    >
                        <i class="fa fa-comment"></i>
                    </a>
                </li>
            
        
        <li class="post-action">
            
                <a class="post-action-btn btn btn--default" href="#" aria-label="Back to top">
            
                <i class="fa fa-list" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>


        
        
            
                <div id="gitalk"></div>

            
        
    </div>
</article>



                <footer id="footer" class="main-content-wrap">
    <span class="copyrights">
        Copyrights &copy; 2020 Tang Huan. All Rights Reserved.
    </span>
</footer>

            </div>
            
                <div id="bottom-bar" class="post-bottom-bar" data-behavior="4">
                    <div class="post-bar-actions-wrap">
    <div class="post-actions post-action-share">
        <div class="post-action">
            
                <a class="post-bar-action-btn btn btn--default" href="#" aria-label="Back to top">
            
                <i class="fas fa-angle-up" aria-hidden="true"></i>
            </a>
        </div>
        
            
                <div class="post-action">
                    <a 
                        class="post-bar-action-btn btn btn--default"
                        href="#gitalk"
                        aria-label="Leave a comment"
                    >
                         <i class="fas fa-angle-down"></i>
                    </a>
                </div>
            
        
    </div>
</div>
                </div>
                
    <div id="share-options-bar" class="share-options-bar" data-behavior="4">
        <i id="btn-close-shareoptions" class="fa fa-times"></i>
        <ul class="share-options">
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="https://www.facebook.com/sharer/sharer.php?u=https://tangh.github.io/articles/frequently-used-built-in-loss-functions/"
                        aria-label="Share on Facebook"
                    >
                        <i class="fab fa-facebook" aria-hidden="true"></i><span>Share on Facebook</span>
                    </a>
                </li>
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="https://twitter.com/intent/tweet?text=https://tangh.github.io/articles/frequently-used-built-in-loss-functions/"
                        aria-label="Share on Twitter"
                    >
                        <i class="fab fa-twitter" aria-hidden="true"></i><span>Share on Twitter</span>
                    </a>
                </li>
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="http://service.weibo.com/share/share.php?&amp;title=https://tangh.github.io/articles/frequently-used-built-in-loss-functions/"
                        aria-label="Share on Weibo"
                    >
                        <i class="fab fa-weibo" aria-hidden="true"></i><span>Share on Weibo</span>
                    </a>
                </li>
            
                
                
                <li class="share-option">
                    <a
                        class="share-option-btn"
                        target="new"
                        href="http://connect.qq.com/widget/shareqq/index.html?url=https://tangh.github.io/articles/frequently-used-built-in-loss-functions/&amp;title=深度學習中一些常用的內建損失函数"
                        aria-label="Share on QQ"
                    >
                        <i class="fab fa-qq" aria-hidden="true"></i><span>Share on QQ</span>
                    </a>
                </li>
            
        </ul>
    </div>


            
        </div>
        


    
        
    

<div id="about">
    <div id="about-card">
        <div id="about-btn-close">
            <i class="fa fa-times"></i>
        </div>
        
            <img id="about-card-picture" src="/assets/images/icon.jpg" alt="Author&#39;s picture"/>
        
            <h4 id="about-card-name">Tang Huan</h4>
        
            <div id="about-card-bio"></div>
        
        
            <div id="about-card-job">
                <i class="fa fa-briefcase"></i>
                <br/>
                
            </div>
        
        
            <div id="about-card-location">
                <i class="fa fa-map-marker-alt"></i>
                <br/>
                Shanghai
            </div>
        
    </div>
</div>

        
        
<div id="cover" style="background-image:url('/assets/images/cover.jpg');"></div>
        

<!--SCRIPTS-->

<script src="/assets/js/script-21vlobaq8sfmdbypn0z91hl6jyot6shixuux8ijser2jcbktmikbwlb6yvjx.min.js"></script>

<!--SCRIPTS END-->


    
      <script type="text/javascript">
        (function() {
          function render() {
            new Gitalk({
              clientID: 'b7b365f41dbbfaaf9b88',
              clientSecret: '25de272b8030e3c498dd56b883e4386d881b6d62',
              repo: 'tangh.github.io',
              owner: 'tangh',
              admin: ['tangh'],
              id: 'articles/frequently-used-built-in-loss-functions',
              title: document.title.replace(' - 雨天等放晴', ''),
              ...{"language":"en","perPage":10,"distractionFreeMode":false,"enableHotKey":true,"pagerDirection":"first","createIssueManually":true}
            }).render('gitalk');
          }
          var gc = document.createElement('script');
          gc.type = 'text/javascript';
          gc.src = '//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js';
          gc.charset = 'UTF-8';
          gc.onload = render;
          gc.async = true;
          document.querySelector('body').appendChild(gc);
          var gcs = document.createElement('link');
          gcs.href = '//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css';
          gcs.type = 'text/css';
          gcs.rel = 'stylesheet';
          gcs.media = 'screen,print';
          document.querySelector('head').appendChild(gcs);
        })();
      </script>
    




    <script>!function(e){var c=Array.prototype.slice.call(document.querySelectorAll("img[data-original]"));function i(){for(var r=0;r<c.length;r++)t=c[r],(n=t.getBoundingClientRect()).top>=-n.height&&0<=n.left&&n.top<=1.5*(e.innerHeight||document.documentElement.clientHeight)&&function(){var t,n,e,i,o=c[r];t=o,n=function(){c=c.filter(function(t){return o!==t})},e=new Image,i=t.getAttribute("data-original"),e.onload=function(){t.src=i,n&&n()},e.src=i}();var t,n}i(),e.addEventListener("scroll",function(){var t,n;t=i,n=e,clearTimeout(t.tId),t.tId=setTimeout(function(){t.call(n)},500)})}(this);</script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end --></body>
</html>
